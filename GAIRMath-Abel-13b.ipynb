{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c702a27-cf72-47cd-aa06-f0cc81714355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda:5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0893de-9180-4b10-aa0f-4b374672cf3e",
   "metadata": {},
   "source": [
    "# GAIRMath-Abel-13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c205889-1d7a-43af-a11e-a2d3e627d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定本地模型路径\n",
    "# model_path = \"/data1/ckpts/Aquila2-34B/\"\n",
    "# model_path = \"/data1/ckpts/Baichuan-13B-Base/\"\n",
    "# model_path = \"/data1/ckpts/Baichuan-7B/\"\n",
    "# model_path = \"/data1/ckpts/Baichuan2-7B-Base/\"\n",
    "# model_path = \"/data1/ckpts/chatglm-6b/\"\n",
    "model_path = \"/data1/ckpts/GAIRMath-Abel-13b/\"\n",
    "# model_path = \"/data1/ckpts/GAIRMath-Abel-7b/\"\n",
    "# model_path = \"/data1/ckpts/phi-1_5/\"\n",
    "# model_path = \"/data1/ckpts/Qwen-7B/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a54c9e-9b16-49cd-9c87-64c790000df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1b4bcf60fe45c2814a4acbef7942f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 使用本地模型路径加载分词器和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True).half().to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16b9a83-edb9-4056-be83-1511dda4e483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [14:00<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Perplexity of the dataset_train: 4.093652076340257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1319/1319 [02:31<00:00,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Perplexity of the dataset_test: 12.659963563321845\n",
      "Difference(test - train): 8.566311486981588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ppl(dataset, model, tokenizer, device):\n",
    "    ppls = []\n",
    "\n",
    "    for question, answer in tqdm(zip(dataset['question'], dataset['answer']), total=len(dataset['question'])): \n",
    "        combined_text = question + '\\n\\n' + answer\n",
    "        encodings = tokenizer(combined_text, return_tensors='pt')\n",
    "\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        labels = torch.cat([input_ids[:, 1:], torch.tensor([[tokenizer.eos_token_id]], device=device)], dim=1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., :-1].contiguous()\n",
    "\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        losses = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "        log_likelihood = losses.sum() / losses.numel()\n",
    "        perplexity = torch.exp(log_likelihood)\n",
    "        ppls.append(perplexity.item())\n",
    "        \n",
    "    return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}\n",
    "\n",
    "# 加载本地数据集\n",
    "dataset_train = load_dataset('json', data_files='/data/rjxu/gsm8k_train.jsonl', split='train')\n",
    "dataset_test = load_dataset('json', data_files='/data/rjxu/gsm8k_test.jsonl', split='train')\n",
    "\n",
    "average_train_ppl = calculate_ppl(dataset_train, model, tokenizer, device)\n",
    "print(f'Average Perplexity of the dataset_train: {average_train_ppl[\"mean_perplexity\"]}')\n",
    "average_test_ppl = calculate_ppl(dataset_test, model, tokenizer, device)\n",
    "print(f'Average Perplexity of the dataset_test: {average_test_ppl[\"mean_perplexity\"]}')\n",
    "print(f'Difference(test - train): {average_test_ppl[\"mean_perplexity\"]-average_train_ppl[\"mean_perplexity\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
